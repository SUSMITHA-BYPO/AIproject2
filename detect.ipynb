import cv2
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow.keras as tfk
import tensorflow_datasets as tfds
import keras
from keras import layers
from keras.preprocessing import image
tfkl = tfk.layers
path = "/kaggle/input/fashion-product-images-dataset/fashion-dataset/fashion-dataset/"
print(os.listdir(path))
df = pd.read_csv(path + "styles.csv", nrows=5000, error_bad_lines=False)
df['image'] = df.apply(lambda row: str(row['id']) + ".jpg", axis=1)
df = df.reset_index(drop=True)
df.head(10)
test_id = 15970
def retrieval(df,image_id):
    selected_rows = df.loc[df['image'] == str(image_id)+'.jpg']
    sub_cat = selected_rows['subCategory'].iloc[0]
    gender = selected_rows['gender'].iloc[0]
    retr_dt = df.loc[(df['subCategory']==sub_cat) & (df['gender']==gender)]#retrived dataset
    return retr_dt
retr_dt = retrieval(df,test_id)
retr_dt.head(5)
def read_image(image_id):
    img = str(image_id)+'.jpg'
    img = cv2.imread(path+"images/"+str(img))
    #print(img.shape)
    if img.shape != (2400,1800,3):
        img = image.load_img(path+"images/"+str(image_id)+'.jpg', target_size=(2400,1800,3))
        img = image.img_to_array(img)
    return img
def plot_image(image_id):
    img = str(image_id)+'.jpg'
    img = cv2.imread(path+"images/"+str(img))
    # If directly use cv2.imshow(img)m, the color is in wrong order
    b,g,r = cv2.split(img)
    frame_rgb = cv2.merge((r,g,b))
    plt.imshow(frame_rgb)
plot_image(test_id)
def with_without_model(test_id):
    execution_path = "/kaggle/input/fashion-product-images-dataset/fashion-dataset/images/"
    detector = ObjectDetection()
    detector.setModelTypeAsRetinaNet()
    detector.setModelPath("/kaggle/input/imageai/resnet50_coco_best_v2.0.1.h5")
    detector.loadModel()
    
    detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path,str(test_id)+".jpg"), output_image_path=os.path.join(os.getcwd(),str(test_id)+".jpg"))
    
    for eachObject in detections:
        if eachObject["name"]=='person' and eachObject["percentage_probability"]>50:
            return 1
        else:
            continue
    return 0
from keras.applications.resnet50 import ResNet50

tfkl = tfk.layers
#remember the input_shape set for this model is in_shape, which is a tuple, so the image should be resized
def build_model(in_shape,high_d=True):
    #build model for embedding
    resnet_base = ResNet50(weights='imagenet', 
                      include_top=False, 
                      input_shape = in_shape)
    resnet_base.trainable = False
    
    model = tfk.Sequential()
    model.add(resnet_base)
    if high_d==True:
        model.add(tfkl.GlobalMaxPooling2D()) #add layer embedding
    else:
        model.add(tfkl.Dense(100, activation=tf.nn.relu))
    
    print(model.summary())
    return model
    img = read_image(test_id)
emb = model.predict(img.reshape(tuple([1]+in_shape))) #(1, 2400, 1800, 3)
# emb
## convert the shape (1,2048) to (2048,)
emb = emb.reshape(-1)

emb.shape
emb
def get_embedding(mod, image_name, in_shape):
    # Reshape and load image
    img = image.load_img(path+"images/"+str(image_name), target_size=in_shape)
    img = image.img_to_array(img)
    ## img = cv2.imread(path+"images/"+str(image_name))
    return mod.predict(img.reshape(tuple([1]+in_shape))).reshape(-1)
numRows = df.shape[0]
numCols = 2048 #representing dimensions for embedding, see the output dim of model
emb_matrix = pd.DataFrame(index=range(numRows),columns=range(numCols))
# Compute every image's embedding in df, and attach it as a column
for r in range(0,df.shape[0]):
    im = df['image'][r]
    emb = get_embedding(model,im,in_shape)
    emb_matrix.iloc[r,:]=emb
emb_matrix.to_csv("emb_matrix.csv",index=False)
emb_store = pd.concat([emb_matrix, df[["image","id"]]],axis=1,ignore_index=False)
emb_store.to_csv("emb_store.csv",index=True)
compute similarity for all retrieved images
#retr_dt.index
dt = emb_store.loc[retr_dt.index,]
dt.head(5)
def compute_similarity(dt,test_id):
    dt.index = dt["id"].apply(str)
    dt["sim"] = np.nan
    try:
        dt = dt.drop(["image","id"],axis=1)
    except:
        dt = dt
    target_vec = dt.loc[dt.index==str(test_id)]
    target_vec = list(target_vec.iloc[0,0:2048])
    #again, 2048 represents dimensions for embedding, see the output dim of model
    
    from scipy import spatial
    for i in dt.index:
        vec = dt.loc[dt.index==i, dt.columns!="sim"]
        vec = list(vec.iloc[0,:])
        cosine_similarity = 1 - spatial.distance.cosine(target_vec, vec)
        dt.loc[dt.index==i,"sim"] = round(cosine_similarity,3)
    
    sort_dt = dt.sort_values('sim',ascending=False)
    
    return sort_dt
sorted_dat = compute_similarity(dt, test_id)
sorted_dat.head(5)
#plot the top 10 recommendations for test_id
fig=plt.figure(figsize=(10, 10))
columns = 5
rows = 2
i = 1
for img in sorted_dat.iloc[0:10,i].index:
    im = cv2.imread(path+"images/"+str(img)+".jpg")
    b,g,r = cv2.split(im)
    frame_rgb = cv2.merge((r,g,b))
    fig.add_subplot(rows, columns, i)
    plt.imshow(frame_rgb)
    i+=1
plt.show()
